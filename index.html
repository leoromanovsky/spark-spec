<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <title>Spark Spec by leoromanovsky</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>Spark Spec</h1>
        <h2>Testing utilities for Apache Spark.</h2>

        <section id="downloads">
          <a href="https://github.com/leoromanovsky/spark-spec/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/leoromanovsky/spark-spec/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/leoromanovsky/spark-spec" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <h1>
<a id="spark-spec" class="anchor" href="#spark-spec" aria-hidden="true"><span class="octicon octicon-link"></span></a>Spark Spec</h1>

<p>This project is a collection of utility classes to make ease testing Apache Spark programs.</p>

<pre><code>class SimpleExampleSpec extends SparkSpecUtils with ShouldMatchers {
  sparkTest("spark parallelize") {
    val data = sc.parallelize(1 to 1e6.toInt)
    val result = data.filter{_ % 2 == 0}.count
    println("Result:", result)
    result should be (5e5.toInt)
  }
}

&gt; test-only com.strava.discovery.SimpleSparkTest
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/03/01 12:02:05 INFO SecurityManager: Changing view acls to: foo
...
...
15/03/01 12:02:07 INFO DAGScheduler: Stage 0 (count at SimpleSparkTest.scala:9) finished in 0.095 s
15/03/01 12:02:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
15/03/01 12:02:07 INFO SparkContext: Job finished: count at SimpleSparkTest.scala:9, took 0.206779 s
(Result:,500000)
15/03/01 12:02:07 INFO SparkUI: Stopped Spark web UI at http://192.168.8.103:4040
15/03/01 12:02:07 INFO DAGScheduler: Stopping DAGScheduler
15/03/01 12:02:08 INFO MapOutputTrackerMasterActor: MapOutputTrackerActor stopped!
15/03/01 12:02:08 INFO ConnectionManager: Selector thread was interrupted!
15/03/01 12:02:08 INFO ConnectionManager: ConnectionManager stopped
15/03/01 12:02:08 INFO MemoryStore: MemoryStore cleared
15/03/01 12:02:08 INFO BlockManager: BlockManager stopped
15/03/01 12:02:08 INFO BlockManagerMaster: BlockManagerMaster stopped
15/03/01 12:02:08 INFO SparkContext: Successfully stopped SparkContext
[info] SimpleSparkTest:
[info] - spark filter
[info] Run completed in 3 seconds, 465 milliseconds.
[info] Total number of tests run: 1
[info] Suites: completed 1, aborted 0
[info] Tests: succeeded 1, failed 0, canceled 0, ignored 0, pending 0
[info] All tests passed.
[success] Total time: 4 s, completed Mar 1, 2015 12:02:08 PM
</code></pre>

<p>The Spark cluster was launched in local mode behind the scenes, kept around for the duration of the specs in the 
class, and shutdown afterwards.</p>

<p>I've divided it into two directories:</p>

<ul>
<li>core - The library which a developer includes into their project.</li>
<li>examples - A standalone sbt project meant to be fully transferable.</li>
</ul>

<h2>
<a id="getting-started" class="anchor" href="#getting-started" aria-hidden="true"><span class="octicon octicon-link"></span></a>Getting Started</h2>

<p>In your Build.scala: </p>

<pre><code>libraryDependencies ++= Seq("com.leoromanovsky" %% "spark-spec-core" % "0.0.1-SNAPSHOT" % "test")
</code></pre>

<p>Add a spec to test <code>MyETLJob</code> class:</p>

<pre><code>package com.strava.discovery.etl

import com.leoromanovsky.sparkspec.core.SparkSpecUtils
import org.scalatest.ShouldMatchers
import com.foo.etl.MyETLJob

class MyETLJobSpec extends SparkSpecUtils with ShouldMatchers {
  sparkTest("my etl") {
    val results = MyETLJob.runJob(sc, config)
    println("Result:", results)
    results should be (1)
  }
}
</code></pre>

<p>The test passed in a <code>SparkContext</code> and <code>Config</code> as <code>sc</code> and <code>config</code>, respectfully.</p>

<h2>
<a id="contributing" class="anchor" href="#contributing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contributing</h2>

<p>I welcome feedback, issue reports and pull requests.</p>

<p>Leo</p>
      </section>
    </div>

              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-60245074-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>